\documentclass{article}

\usepackage[final]{nips_2016}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsmath}

\title{Deep Learning --- Assignment 3}

\author{Anirudhan J.~Rajagopalan \\
  Department of Computer Science\\
  New York University\\
  New York, NY.\\
  \texttt{ajr619@nyu.edu} \\
}

\begin{document}

\maketitle

\section{Variants of Pooling}
Pooling is an operation in Convolutional Neural Networks which is performed after a convolutional layer.  
We decide on a size of the region to do pool our convolutional filters over.
Then we divide the convolved features into disjoint regions and take the max, mean or norm of the feature activations depending on the type of pooling operation.
Generally the stride length used in pooling is equal to the pooling window size.
\subsection{Three types of pooling}
There are three types of pooling operations that are used
\begin{description}
  \item[Max pooling] Max pooling takes the maximum of the feature activations.  Implemented by \mbox{SpatialMaxPooling}.
  \item[Average pooling] Average pooling takes the average of the feature activations. Implemented by \mbox{SpatialAveragePooling}.
  \item[Lp pooling] LpPooling takes the lp norm of the feature activations. Implemented by \mbox{SpatialLPPooling}.
\end{description}

\subsection{Mathematical formulas for pooling}
Suppose we have a $N x N$ convolutional layer (filters) and a pooling layer of size $m x m$ where $ m < N $
The pooling operation is generally implemented using a stride of m.
Therefore the size of filters after pooling will be $\frac{N}{m} * \frac{N}{m} $ and each of the $m x m$ pooling operations gives a single value.
The single value for a pooling operation can be represented by
\begin{align*}
  y = \sigma(x_{ij})
\end{align*}
where $1 \le i \le m $ and $1 \le j \le m $.
\subsubsection{MaxPooling}
Incase of max pooling
\begin{align*}
  \sigma = \max(x_{ij}) \qquad 1 \le i \le m and 1 \le j \le m
\end{align*}

\subsubsection{Average Pooling}
Incase of average pooling
\begin{align*}
  \sigma = \frac{\sum_{i=1}^{m} \sum_{j=1}^{m} x_{ij}}{m*m}
\end{align*}

\subsubsection{LPPooling}
Incase of LP pooling where $p \ge 2$.
\begin{align*}
  \sigma = {(\sum_{i=1}^{m}\sum_{j=1}^{m} x_{ij}^{p} )}^{\frac{1}{p}}
\end{align*}

\subsection{Reason for using in deep learning}
Pooling is used for a number of reasons.
\begin{enumerate}
  \item Computational tractability.  The number of features after convolution increases by $numFIlters x (N-m+1) x (N-m+1)$.  Generally it will be computationally intractable to perform learning on this huge data.
  \item Overfitting.  Since the number of features are high, this will lead to overfitting.  Pooling helps in reducing the number of features.
  \item Stationary property.  Generally images have stationary property.  This means that features that are useful in one region will be useful in other regions also.  Pooling operation helps in aggregating the features at various locations.
\end{enumerate}

We generally use Max-pooling for images as the performance of Max pooling has been emperically shown to be better than Average or Lp pooling for image workflows.  This can be explained by the stationary property of the image as the most important activation in a small patch can be found by using max pooling.

\section{Convolution}
\subsection{Number of values after forward propogation}
When we apply a convolution on a $N \times N$ image with a kerenel of size $ m \times m $ we get $(N-m+1) \times (N-m+1)$ output values after the convolution.

Here, N = 5, m = 3.
Therefore we will get $(5-3+1) \times (5-3+1) = 9$ values.
\subsection{Values after forward propogation}
The resulting filter obtained by applying the convolutional kernel is:
\begin{centering}
  \begin{align*}
  109 &\qquad 92 \qquad 72 \\
  108 &\qquad 85 \qquad 74 \\
  110 &\qquad 74 \qquad 79
  \end{align*}
\end{centering}

\subsection{Value of gradient}
\begin{centering}
\begin{align*}
4 & \qquad 7 & \qquad 10 &\qquad 6 & \qquad 3\\
9 & \qquad 17 &\qquad  25 & \qquad  16 & \qquad   8\\
11 & \qquad 23 & \qquad  34 & \qquad  23 & \qquad  11\\
7 & \qquad 16 & \qquad  24 & \qquad  17 & \qquad   8\\
2 & \qquad 6 & \qquad 9 & \qquad   7 & \qquad   3
\end{align*}
\end{centering}

\section{Optimization}
\subsection{Mathematical formula for reconstruction loss}
\subsection{Gradient of the loss with respect to the loss}
\subsection{Gradient descent step}
\subsection{Gradient step with momentum}

\section{Top-k error}
\subsection{Definition}
Top-k error is an error metric used in ranking problems.  
This is the number of samples, $x_{i}$ with correct labels $ y_{i} $ that doesn't appear in the top-k predicted results of the model in the order of the probability measure or score used for ranking.  
According to LVSRC 2014 by Imagenet~\cite{ILSVRC15}, the error is defined as
\begin{align*}
  e =& \frac{1}{n}. \sum_{k} \min_{i} d(c_{i}, C_{k})
\end{align*}
where $C_{k}$ is the ground truth of the image with k = 1, \ldots, n labels.\ 
and $c_{i}$ is the labels generated by the classification algorithm with i $\in$ 1, \ldots 5.

Given this formulation, using the top-5 error helps us not to penalize a classification algorithm if it finds an object in an image which is not present in ground truth.

Using top-1 error ensures how close the object identified in the image by an algorithm is with respect to the original image in imagenet database.

\section{t-SNE}
\subsection{Crowding problem}
\subsection{Derive $\frac{\partial C}{\partial y_{i}}$}

\bibliographystyle{plain}
\bibliography{references}

\end{document}
